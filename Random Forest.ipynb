{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo : Adding the input of feature selction method\n",
    "# Todo ; Adding the input of bootstap sample number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(*groups):\n",
    "    gini_value = 0\n",
    "    total_num = np.sum([group[0].shape[0] for group in groups])\n",
    "\n",
    "    for group in groups:\n",
    "        y = group[1]\n",
    "        group_size = y.shape[0]\n",
    "\n",
    "        _, count = np.unique(y, return_counts=True)\n",
    "        p = count/group_size\n",
    "        weight = group_size/total_num\n",
    "\n",
    "        gini_value += (1- np.sum(p**2)) * weight\n",
    "    return gini_value\n",
    "\n",
    "\n",
    "def split(X, y, split_value):\n",
    "    mask = X < split_value\n",
    "    group_1 = (X[mask], y[mask])\n",
    "    group_2 = (X[mask == 0], y[mask == 0])\n",
    "    return group_1, group_2\n",
    "\n",
    "def best_split(X, y, m = None):\n",
    "    spliting_list = []\n",
    "    feature_index = np.arange(X.shape[1])\n",
    "    \n",
    "    if m != None:\n",
    "        feature_index = np.random.choice(feature_index, 2, replace=False)\n",
    "        \n",
    "    for i in feature_index:\n",
    "        split_range = np.unique(X[:,i])\n",
    "        for split_value in split_range:\n",
    "            split_group = split(X[:, i], y, split_value)\n",
    "            if check_legal_split(*split_group, min_samples_leaf=1):\n",
    "                spliting_list.append([gini_index(*split_group), split_value, i])\n",
    "               \n",
    "    if len(spliting_list) ==0:\n",
    "#         print('No Data can be split')\n",
    "        return np.NaN, np.NaN, None, None\n",
    "    else:\n",
    "        optimal_split, _,_ = np.argmin(np.array(spliting_list), axis = 0)\n",
    "        _, optimal_split_value, label = np.array(spliting_list[optimal_split])\n",
    "\n",
    "        bool_mask = X[:, int(label)] < optimal_split_value\n",
    "        group1 = (X[bool_mask], y[bool_mask])\n",
    "        group2 = (X[bool_mask == 0 ], y[bool_mask == 0])\n",
    "        return optimal_split_value, label, group1, group2\n",
    "\n",
    "def check_legal_split(*groups, min_samples_leaf=1):\n",
    "    for group in groups:\n",
    "        if group[0].shape[0] < min_samples_leaf:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "def pprint_tree(node, file=None, _prefix=\"\", _last=True):\n",
    "    print(_prefix, \"`- \" if _last else \"|- \", \"Depth :{}, Split Feature:{}, Split Value:{}, Label:{}\".format(node.depth,node.split_value, node.split_feature, node._label), sep=\"\", file=file)\n",
    "    _prefix += \"   \" if _last else \"|  \"\n",
    "    \n",
    "    if node._left_child == None or node._right_child == None:\n",
    "        return None\n",
    "    \n",
    "    pprint_tree(node._left_child, file, _prefix, _last = False)\n",
    "    pprint_tree(node._right_child, file, _prefix, _last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, depth = 0):\n",
    "        self.split_value = None\n",
    "        self.split_feature = None\n",
    "        self._label = None\n",
    "        self._left_child = None\n",
    "        self._right_child = None\n",
    "        self._leaf = False\n",
    "        self.depth = depth\n",
    "    \n",
    "    def train(self, X, y, max_depth=8, min_samples_split=2, min_samples_leaf=1):\n",
    "        m = int(np.sqrt(X.shape[1]))\n",
    "#         print('Depth', self.depth)\n",
    "#         print('Sample', X.shape[0])\n",
    "#         print('X ', X)\n",
    "#         print('y ', y)\n",
    "\n",
    "    \n",
    "        self.split_value, self.split_feature, group1, group2 = best_split(X, y, m = m)\n",
    "        \n",
    "        if group1 == None and group2 == None:\n",
    "            self.sprout(y)\n",
    "        else:\n",
    "            if self.depth < max_depth and X.shape[0] > min_samples_split and len(np.unique(X)) != len(X[0]):\n",
    "                self._left_child = Node(self.depth + 1)\n",
    "                self._right_child = Node(self.depth + 1)\n",
    "                self._left_child.train(*group1, max_depth, min_samples_split, min_samples_leaf)\n",
    "                self._right_child.train(*group2, max_depth, min_samples_split, min_samples_leaf)\n",
    "            else:\n",
    "                self.sprout(y)\n",
    "            \n",
    "    def sprout(self, y):\n",
    "        self._leaf = True\n",
    "\n",
    "        labels, count = np.unique(y, return_counts = True)\n",
    "        self._label = labels[np.argmax(count)]\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if self._leaf == True:\n",
    "            return self._label\n",
    "        \n",
    "        if x[int(self.split_feature)] < self.split_value:\n",
    "            return self._left_child.predict(x)\n",
    "        else:\n",
    "            return self._right_child.predict(x)\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self, max_depth=8, min_samples_split=2, min_samples_leaf=1):\n",
    "        self._root = Node()\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "    def train(self, X, y, bootstrap = False):\n",
    "        \n",
    "        if bootstrap == True:\n",
    "            N = X_train.shape[0]\n",
    "            X_range = np.arange(N)\n",
    "            index = np.random.choice(X_range, N, replace=True)\n",
    "            X = X[index]\n",
    "            y = y[index]\n",
    "        \n",
    "        self._root.train(X, y,\n",
    "                        self.max_depth, \n",
    "                        self.min_samples_split, \n",
    "                        self.min_samples_leaf)\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = []\n",
    "        for i in range(len(X)):\n",
    "            prediction.append(self._root.predict(X[i]))\n",
    "        return prediction\n",
    "    \n",
    "    def print_tree(self):\n",
    "        pprint_tree(self._root)\n",
    "\n",
    "class Forest:\n",
    "    def __init__(self, max_depth=8, min_samples_split=2, min_samples_leaf=1, \n",
    "                 n_estimators = 100):\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.n_estimators = n_estimators\n",
    "        self.trees = []\n",
    "    \n",
    "    def train(self, X, y, bootstrap = False, bootstrap_ratio = 0):\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = Tree(max_depth=4)\n",
    "            tree.train(X,y,bootstrap = True)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        trees_result = np.array([tree.predict(X) for tree in self.trees])\n",
    "        unqiue_count = list(map(lambda x : np.unique(x, return_counts = True),trees_result.T))\n",
    "        index = [np.argmax(x[1]) for x in unqiue_count]\n",
    "        labels = [x[0] for x in unqiue_count]\n",
    "        return np.array([label[indices] for label, indices in zip(labels, index)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([[5.,  3.2, 1.2, 0.2],\n",
    "                   [5.8, 4. , 1.2, 0.2],\n",
    "                   [5.,  3.2 ,1.2, 0.2]])\n",
    "y_test = np.array([0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Data can be split\n"
     ]
    }
   ],
   "source": [
    "spliting_list = []\n",
    "feature_index = np.arange(X.shape[1])\n",
    "\n",
    "if m != None:\n",
    "    feature_index = np.random.choice(feature_index, 2, replace=False)\n",
    "\n",
    "for i in feature_index:\n",
    "    split_range = np.unique(X[:,i])\n",
    "    for split_value in split_range:\n",
    "        split_group = split(X[:, i], y, split_value)\n",
    "        if check_legal_split(*split_group, min_samples_leaf=1):\n",
    "            spliting_list.append([gini_index(*split_group), split_value, i])\n",
    "\n",
    "if len(spliting_list) ==0:\n",
    "    print('No Data can be split')\n",
    "#     return np.NaN, np.NaN, None, None\n",
    "else:\n",
    "    optimal_split, _,_ = np.argmin(np.array(spliting_list), axis = 0)\n",
    "    _, optimal_split_value, label = np.array(spliting_list[optimal_split])\n",
    "\n",
    "    bool_mask = X[:, int(label)] < optimal_split_value\n",
    "    group1 = (X[bool_mask], y[bool_mask])\n",
    "    group2 = (X[bool_mask == 0 ], y[bool_mask == 0])\n",
    "#     return optimal_split_value, label, group1, group2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check with sckit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0,\n",
    "                                 n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "skprediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = Forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_result = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, trees_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skprediction == trees_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
